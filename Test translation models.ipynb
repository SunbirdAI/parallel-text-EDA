{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c744627-5999-41de-a6c0-b080e8767388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sacremoses\n",
    "import tqdm\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107f749-6e2f-491e-85b6-52db3b78a7cc",
   "metadata": {},
   "source": [
    "Change the paths here accordingly, to the locations of saved checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9c277e-5d80-495b-ac2e-81cd9b3f3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_en_checkpoint_path = \"savedmodels/mul-en\"\n",
    "mul_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    mul_en_checkpoint_path)\n",
    "mul_en_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    mul_en_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7da546a0-a64c-464b-a7c9-751fc4c139d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_mul_checkpoint_path = \"savedmodels/en-mul\"\n",
    "en_mul_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    en_mul_checkpoint_path)\n",
    "en_mul_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    en_mul_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c8356-114a-43dc-b174-c9b4fe478176",
   "metadata": {},
   "source": [
    "We run the model on CPU, so that this can be done while the model is training (no extra GPU memory taken)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87719261-e546-4e1d-89d8-8efce8a455a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_format(input, first_word_title_case = True): \n",
    "    '''Ensure capital letter at the start and full stop at the end.'''\n",
    "    input = input[0].capitalize() + input[1:]\n",
    "    if input[-1] not in ['.', '!', '?']:\n",
    "        input = input + '.'\n",
    "    return input\n",
    "\n",
    "def translate(source_text, model, tokenizer):\n",
    "    device = torch.device('cpu')\n",
    "    model = model.eval()\n",
    "    model = model.to(device) \n",
    "    inputs = tokenizer(source_text, return_tensors=\"pt\").to(device)\n",
    "    tokens = model.generate(**inputs)\n",
    "    result = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "def translate_to_multiple(query,\n",
    "                          languages = {'ach': 'Acholi', 'lgg': 'Lugbara',\n",
    "                                       'lug': 'Luganda','nyn': 'Runyankore',\n",
    "                                       'teo': 'Ateso'}):\n",
    "    normalizer = sacremoses.MosesPunctNormalizer()\n",
    "    normalized_query = sentence_format(normalizer.normalize(query))\n",
    "    \n",
    "    translations = []\n",
    "    for lang in ['lug', 'ach', 'nyn', 'teo', 'lgg']:\n",
    "        translation = translate(f\">>{lang}<< {normalized_query}\",\n",
    "                                en_mul_model, en_mul_tokenizer)\n",
    "        translations.append({'target': languages[lang],\n",
    "                             'translation': translation})\n",
    "\n",
    "    df = pd.DataFrame(translations)\n",
    "    df = df.set_index('target')   \n",
    "    return df\n",
    "\n",
    "def translate_to_english(query):\n",
    "    normalizer = sacremoses.MosesPunctNormalizer()\n",
    "    normalized_query = sentence_format(normalizer.normalize(query))\n",
    "    return translate(normalized_query, mul_en_model, mul_en_tokenizer)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9e131343-fc87-47cd-a424-211ea005d185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Luganda</th>\n",
       "      <td>Enkuba eyinza okutonnya enkya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acholi</th>\n",
       "      <td>Kot romo cwer diki.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runyankore</th>\n",
       "      <td>Enjura nebaasa kugwa nyenkyakare.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ateso</th>\n",
       "      <td>Aticepak edou moi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lugbara</th>\n",
       "      <td>Ozoo eco drusi ra.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  translation\n",
       "target                                       \n",
       "Luganda        Enkuba eyinza okutonnya enkya.\n",
       "Acholi                    Kot romo cwer diki.\n",
       "Runyankore  Enjura nebaasa kugwa nyenkyakare.\n",
       "Ateso                      Aticepak edou moi.\n",
       "Lugbara                    Ozoo eco drusi ra."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "It may rain tomorrow.\n",
    "'''\n",
    "\n",
    "translate_to_multiple(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b1934b3-752b-49d2-9f9c-0d6ff96fa44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lady says she is tired of suffering.'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "Omukyala agamba akooye okubonabona.\n",
    "'''\n",
    "\n",
    "translate_to_english(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034a13b-b200-4cfd-8034-ab6257120b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
