{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compilation of training dataset for Sunbird language models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "from decouple import config\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyMCIyXMqby",
        "outputId": "9a6b8196-db1d-467d-cea1-358a02c1a86b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vRJsiBvySr9GKcqJr_kXW1hRbg_qIEPW\n",
            "To: /Users/lydia/Desktop/sunbird/nlp-eda/sunbird-ug-lang-v4.0.jsonl\n",
            "100%|██████████| 9.10M/9.10M [00:05<00:00, 1.70MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'sunbird-ug-lang-v4.0.jsonl'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id = config(\"RESOURCE_ID\")\n",
        "url = f\"https://drive.google.com/uc?id={id}\"\n",
        "gdown.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oH39MPDcM0yi"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json(\"sunbird-ug-lang-v4.0.jsonl\", lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split data into train, test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2qsiV1p_M_Pi"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(data, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUFpFJqNknc",
        "outputId": "ff0aa255-25a2-4d26-c180-9103f5f75915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14409, 6)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4230D7OPuIO",
        "outputId": "33e47e1d-8fdf-4a9f-c8b1-70784468293a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7098, 6)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HUqes6FyPxju"
      },
      "outputs": [],
      "source": [
        "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b90pziBoQBnI",
        "outputId": "264863ce-c9e6-4931-dc42-40f30bc4bec1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3549, 6)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLdoRWyEQE7Y",
        "outputId": "23847bff-c69b-4861-8452-5ec29127ede1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3549, 6)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou79-f3sQRKm"
      },
      "source": [
        "## Create the .txt files needed for the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "language_list = list(data.columns)\n",
        "language_codes = {\n",
        "    \"English\": \"en\", \"Luganda\": \"lug\", \"Runyankole\": \"run\", \n",
        "    \"Acholi\": \"ach\", \"Ateso\": \"teo\", \"Lugbara\": \"lgg\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Array of pairs to be used in later refactoring\n",
        "pairs = [\n",
        "    \"en-lug\", \"en-run\", \"en-ach\", \"en-teo\", \"en-lgg\", \"lug-ach\", \"lug-run\", \"lug-lgg\", \n",
        "    \"lug-teo\", \"ach-run\", \"ach-lgg\", \"ach-teo\", \"teo-lgg\", \"teo-run\", \"run-lgg\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "for language in language_list:\n",
        "    train_df[language].to_csv(f\"train.{language_codes[language]}\", header=False, index=False, sep='\\t', mode='a')\n",
        "    test_df[language].to_csv(f\"test.{language_codes[language]}\", header=False, index=False, sep='\\t', mode='a')\n",
        "    val_df[language].to_csv(f\"val.{language_codes[language]}\", header=False, index=False, sep='\\t', mode='a')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create initial dataset folder and add dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Unf7OAJzTCcv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: dataset: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wizOH70tTHQY"
      },
      "outputs": [],
      "source": [
        "!mv {*.en,*.lug,*.run,*.ach,*.teo,*.lgg} dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQf528eBUPzt",
        "outputId": "30962705-4e1d-4ecc-a974-6310dc8d543d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test.ach  test.lug  train.ach train.lug val.ach   val.lug\n",
            "test.en   test.run  train.en  train.run val.en    val.run\n",
            "test.lgg  test.teo  train.lgg train.teo val.lgg   val.teo\n"
          ]
        }
      ],
      "source": [
        "!ls dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update dataset folder structure and create archive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `TO DO: Refactor this dataset creation code using Python pathlib`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create and update folders for English to other language pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p v4-dataset/v4.0/supervised/\n",
        "!mkdir v4-dataset/v4.0/supervised/en-lug\n",
        "!mkdir v4-dataset/v4.0/supervised/en-ach\n",
        "!mkdir v4-dataset/v4.0/supervised/en-run\n",
        "!mkdir v4-dataset/v4.0/supervised/en-lgg\n",
        "!mkdir v4-dataset/v4.0/supervised/en-teo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset/test.en -> v4-dataset/v4.0/supervised/en-lug/test.en\n",
            "dataset/train.en -> v4-dataset/v4.0/supervised/en-lug/train.en\n",
            "dataset/val.en -> v4-dataset/v4.0/supervised/en-lug/val.en\n",
            "dataset/test.lug -> v4-dataset/v4.0/supervised/en-lug/test.lug\n",
            "dataset/train.lug -> v4-dataset/v4.0/supervised/en-lug/train.lug\n",
            "dataset/val.lug -> v4-dataset/v4.0/supervised/en-lug/val.lug\n",
            "dataset/test.en -> v4-dataset/v4.0/supervised/en-ach/test.en\n",
            "dataset/train.en -> v4-dataset/v4.0/supervised/en-ach/train.en\n",
            "dataset/val.en -> v4-dataset/v4.0/supervised/en-ach/val.en\n",
            "dataset/test.ach -> v4-dataset/v4.0/supervised/en-ach/test.ach\n",
            "dataset/train.ach -> v4-dataset/v4.0/supervised/en-ach/train.ach\n",
            "dataset/val.ach -> v4-dataset/v4.0/supervised/en-ach/val.ach\n",
            "dataset/test.en -> v4-dataset/v4.0/supervised/en-run/test.en\n",
            "dataset/train.en -> v4-dataset/v4.0/supervised/en-run/train.en\n",
            "dataset/val.en -> v4-dataset/v4.0/supervised/en-run/val.en\n",
            "dataset/test.run -> v4-dataset/v4.0/supervised/en-run/test.run\n",
            "dataset/train.run -> v4-dataset/v4.0/supervised/en-run/train.run\n",
            "dataset/val.run -> v4-dataset/v4.0/supervised/en-run/val.run\n",
            "dataset/test.en -> v4-dataset/v4.0/supervised/en-lgg/test.en\n",
            "dataset/train.en -> v4-dataset/v4.0/supervised/en-lgg/train.en\n",
            "dataset/val.en -> v4-dataset/v4.0/supervised/en-lgg/val.en\n",
            "dataset/test.lgg -> v4-dataset/v4.0/supervised/en-lgg/test.lgg\n",
            "dataset/train.lgg -> v4-dataset/v4.0/supervised/en-lgg/train.lgg\n",
            "dataset/val.lgg -> v4-dataset/v4.0/supervised/en-lgg/val.lgg\n",
            "dataset/test.en -> v4-dataset/v4.0/supervised/en-teo/test.en\n",
            "dataset/train.en -> v4-dataset/v4.0/supervised/en-teo/train.en\n",
            "dataset/val.en -> v4-dataset/v4.0/supervised/en-teo/val.en\n",
            "dataset/test.teo -> v4-dataset/v4.0/supervised/en-teo/test.teo\n",
            "dataset/train.teo -> v4-dataset/v4.0/supervised/en-teo/train.teo\n",
            "dataset/val.teo -> v4-dataset/v4.0/supervised/en-teo/val.teo\n"
          ]
        }
      ],
      "source": [
        "!cp -v dataset/*.{en,lug} v4-dataset/v4.0/supervised/en-lug\n",
        "!cp -v dataset/*.{en,ach} v4-dataset/v4.0/supervised/en-ach\n",
        "!cp -v dataset/*.{en,run} v4-dataset/v4.0/supervised/en-run\n",
        "!cp -v dataset/*.{en,lgg} v4-dataset/v4.0/supervised/en-lgg\n",
        "!cp -v dataset/*.{en,teo} v4-dataset/v4.0/supervised/en-teo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create and update folders for inter-language pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir v4-dataset/v4.0/supervised/lug-ach\n",
        "!mkdir v4-dataset/v4.0/supervised/lug-run\n",
        "!mkdir v4-dataset/v4.0/supervised/lug-lgg\n",
        "!mkdir v4-dataset/v4.0/supervised/lug-teo\n",
        "!mkdir v4-dataset/v4.0/supervised/ach-run\n",
        "!mkdir v4-dataset/v4.0/supervised/ach-lgg\n",
        "!mkdir v4-dataset/v4.0/supervised/ach-teo\n",
        "!mkdir v4-dataset/v4.0/supervised/teo-lgg\n",
        "!mkdir v4-dataset/v4.0/supervised/teo-run\n",
        "!mkdir v4-dataset/v4.0/supervised/run-lgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset/test.lug -> v4-dataset/v4.0/supervised/lug-ach/test.lug\n",
            "dataset/train.lug -> v4-dataset/v4.0/supervised/lug-ach/train.lug\n",
            "dataset/val.lug -> v4-dataset/v4.0/supervised/lug-ach/val.lug\n",
            "dataset/test.ach -> v4-dataset/v4.0/supervised/lug-ach/test.ach\n",
            "dataset/train.ach -> v4-dataset/v4.0/supervised/lug-ach/train.ach\n",
            "dataset/val.ach -> v4-dataset/v4.0/supervised/lug-ach/val.ach\n",
            "dataset/test.lug -> v4-dataset/v4.0/supervised/lug-run/test.lug\n",
            "dataset/train.lug -> v4-dataset/v4.0/supervised/lug-run/train.lug\n",
            "dataset/val.lug -> v4-dataset/v4.0/supervised/lug-run/val.lug\n",
            "dataset/test.run -> v4-dataset/v4.0/supervised/lug-run/test.run\n",
            "dataset/train.run -> v4-dataset/v4.0/supervised/lug-run/train.run\n",
            "dataset/val.run -> v4-dataset/v4.0/supervised/lug-run/val.run\n",
            "dataset/test.lug -> v4-dataset/v4.0/supervised/lug-lgg/test.lug\n",
            "dataset/train.lug -> v4-dataset/v4.0/supervised/lug-lgg/train.lug\n",
            "dataset/val.lug -> v4-dataset/v4.0/supervised/lug-lgg/val.lug\n",
            "dataset/test.lgg -> v4-dataset/v4.0/supervised/lug-lgg/test.lgg\n",
            "dataset/train.lgg -> v4-dataset/v4.0/supervised/lug-lgg/train.lgg\n",
            "dataset/val.lgg -> v4-dataset/v4.0/supervised/lug-lgg/val.lgg\n",
            "dataset/test.lug -> v4-dataset/v4.0/supervised/lug-teo/test.lug\n",
            "dataset/train.lug -> v4-dataset/v4.0/supervised/lug-teo/train.lug\n",
            "dataset/val.lug -> v4-dataset/v4.0/supervised/lug-teo/val.lug\n",
            "dataset/test.teo -> v4-dataset/v4.0/supervised/lug-teo/test.teo\n",
            "dataset/train.teo -> v4-dataset/v4.0/supervised/lug-teo/train.teo\n",
            "dataset/val.teo -> v4-dataset/v4.0/supervised/lug-teo/val.teo\n",
            "dataset/test.ach -> v4-dataset/v4.0/supervised/ach-run/test.ach\n",
            "dataset/train.ach -> v4-dataset/v4.0/supervised/ach-run/train.ach\n",
            "dataset/val.ach -> v4-dataset/v4.0/supervised/ach-run/val.ach\n",
            "dataset/test.run -> v4-dataset/v4.0/supervised/ach-run/test.run\n",
            "dataset/train.run -> v4-dataset/v4.0/supervised/ach-run/train.run\n",
            "dataset/val.run -> v4-dataset/v4.0/supervised/ach-run/val.run\n",
            "dataset/test.ach -> v4-dataset/v4.0/supervised/ach-lgg/test.ach\n",
            "dataset/train.ach -> v4-dataset/v4.0/supervised/ach-lgg/train.ach\n",
            "dataset/val.ach -> v4-dataset/v4.0/supervised/ach-lgg/val.ach\n",
            "dataset/test.lgg -> v4-dataset/v4.0/supervised/ach-lgg/test.lgg\n",
            "dataset/train.lgg -> v4-dataset/v4.0/supervised/ach-lgg/train.lgg\n",
            "dataset/val.lgg -> v4-dataset/v4.0/supervised/ach-lgg/val.lgg\n",
            "dataset/test.ach -> v4-dataset/v4.0/supervised/ach-teo/test.ach\n",
            "dataset/train.ach -> v4-dataset/v4.0/supervised/ach-teo/train.ach\n",
            "dataset/val.ach -> v4-dataset/v4.0/supervised/ach-teo/val.ach\n",
            "dataset/test.teo -> v4-dataset/v4.0/supervised/ach-teo/test.teo\n",
            "dataset/train.teo -> v4-dataset/v4.0/supervised/ach-teo/train.teo\n",
            "dataset/val.teo -> v4-dataset/v4.0/supervised/ach-teo/val.teo\n",
            "dataset/test.teo -> v4-dataset/v4.0/supervised/teo-lgg/test.teo\n",
            "dataset/train.teo -> v4-dataset/v4.0/supervised/teo-lgg/train.teo\n",
            "dataset/val.teo -> v4-dataset/v4.0/supervised/teo-lgg/val.teo\n",
            "dataset/test.lgg -> v4-dataset/v4.0/supervised/teo-lgg/test.lgg\n",
            "dataset/train.lgg -> v4-dataset/v4.0/supervised/teo-lgg/train.lgg\n",
            "dataset/val.lgg -> v4-dataset/v4.0/supervised/teo-lgg/val.lgg\n",
            "dataset/test.teo -> v4-dataset/v4.0/supervised/teo-run/test.teo\n",
            "dataset/train.teo -> v4-dataset/v4.0/supervised/teo-run/train.teo\n",
            "dataset/val.teo -> v4-dataset/v4.0/supervised/teo-run/val.teo\n",
            "dataset/test.run -> v4-dataset/v4.0/supervised/teo-run/test.run\n",
            "dataset/train.run -> v4-dataset/v4.0/supervised/teo-run/train.run\n",
            "dataset/val.run -> v4-dataset/v4.0/supervised/teo-run/val.run\n",
            "dataset/test.run -> v4-dataset/v4.0/supervised/run-lgg/test.run\n",
            "dataset/train.run -> v4-dataset/v4.0/supervised/run-lgg/train.run\n",
            "dataset/val.run -> v4-dataset/v4.0/supervised/run-lgg/val.run\n",
            "dataset/test.lgg -> v4-dataset/v4.0/supervised/run-lgg/test.lgg\n",
            "dataset/train.lgg -> v4-dataset/v4.0/supervised/run-lgg/train.lgg\n",
            "dataset/val.lgg -> v4-dataset/v4.0/supervised/run-lgg/val.lgg\n"
          ]
        }
      ],
      "source": [
        "!cp -v dataset/*.{lug,ach} v4-dataset/v4.0/supervised/lug-ach\n",
        "!cp -v dataset/*.{lug,run} v4-dataset/v4.0/supervised/lug-run\n",
        "!cp -v dataset/*.{lug,lgg} v4-dataset/v4.0/supervised/lug-lgg\n",
        "!cp -v dataset/*.{lug,teo} v4-dataset/v4.0/supervised/lug-teo\n",
        "!cp -v dataset/*.{ach,run} v4-dataset/v4.0/supervised/ach-run\n",
        "!cp -v dataset/*.{ach,lgg} v4-dataset/v4.0/supervised/ach-lgg\n",
        "!cp -v dataset/*.{ach,teo} v4-dataset/v4.0/supervised/ach-teo\n",
        "!cp -v dataset/*.{teo,lgg} v4-dataset/v4.0/supervised/teo-lgg\n",
        "!cp -v dataset/*.{teo,run} v4-dataset/v4.0/supervised/teo-run\n",
        "!cp -v dataset/*.{run,lgg} v4-dataset/v4.0/supervised/run-lgg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zip the dataset - ready for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHn8YxIU2sb",
        "outputId": "4f7cd71b-40ca-4d34-e58c-1f04739b6246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: v4-dataset/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/test.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/val.run (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/train.en (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/val.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/train.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-run/test.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/train.lug (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/val.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/test.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/val.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/test.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-teo/train.teo (deflated 67%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/val.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/test.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/train.en (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/val.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/test.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-teo/train.teo (deflated 67%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/test.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/train.lgg (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/val.run (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/test.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/train.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/run-lgg/val.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/test.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/val.run (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/val.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/test.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/train.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-run/train.teo (deflated 67%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/train.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/train.lgg (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/val.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/test.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/test.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-lgg/val.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/train.lug (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/test.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/val.run (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/val.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/test.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-run/train.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/train.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/val.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/test.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/val.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/test.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-teo/train.teo (deflated 67%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/train.lgg (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/train.en (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/val.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/test.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/test.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lgg/val.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/train.lug (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/train.en (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/val.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/val.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/test.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-lug/test.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/train.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/train.en (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/val.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/val.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/test.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/en-ach/test.en (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/train.lgg (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/val.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/test.teo (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/test.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/val.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/teo-lgg/train.teo (deflated 67%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/train.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/test.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/val.run (deflated 64%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/val.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/test.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/ach-run/train.run (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/train.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/train.lug (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/val.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/val.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/test.ach (deflated 63%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-ach/test.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/ (stored 0%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/train.lug (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/train.lgg (deflated 66%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/val.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/test.lug (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/test.lgg (deflated 65%)\n",
            "  adding: v4-dataset/v4.0/supervised/lug-lgg/val.lgg (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r v4-dataset.zip v4-dataset/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "sunbird-dataset.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
