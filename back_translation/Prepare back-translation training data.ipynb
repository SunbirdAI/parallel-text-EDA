{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c744627-5999-41de-a6c0-b080e8767388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sacremoses\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import glob\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf315b1-3702-49f3-b0e7-7f333da06fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c277e-5d80-495b-ac2e-81cd9b3f3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "mul_en_checkpoint_path = \"savedmodels/mul-en\"\n",
    "mul_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    mul_en_checkpoint_path)\n",
    "mul_en_model = mul_en_model.eval().to(device) \n",
    "mul_en_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    mul_en_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da546a0-a64c-464b-a7c9-751fc4c139d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_mul_checkpoint_path = \"savedmodels/en-mul\"\n",
    "en_mul_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    en_mul_checkpoint_path)\n",
    "en_mul_model = mul_en_model.eval().to(device) \n",
    "en_mul_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    en_mul_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af954dfd-64c2-4626-a593-34c993f9ef52",
   "metadata": {},
   "source": [
    "## Translate Luganda and Acholi text for training en-mul model\n",
    "\n",
    "First, read in the single-language text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de025316-9308-45ec-878f-3233b787ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_list(path):\n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        return lines\n",
    "    \n",
    "codes = ['ach', 'lug', 'teo']\n",
    "text = {}\n",
    "for code in codes:\n",
    "    text[code] = []\n",
    "    files = glob.glob(f'back_translation/{code}/*.txt')\n",
    "    for f in files:\n",
    "        text[code].extend(list(set(file_to_list(f))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e009a7c-6006-44ee-a7af-c4f5d6e14d1c",
   "metadata": {},
   "source": [
    "Use the mul-en model to get English translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74137fdd-b740-427d-af1c-a96adcae85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text up into batches that will fit on the GPU\n",
    "normalizer = sacremoses.MosesPunctNormalizer()\n",
    "\n",
    "def batch_translate(text, batch_size = 20):\n",
    "    translations = []\n",
    "    batches = [\n",
    "        text[i:i + batch_size]\n",
    "        for i in range(0, len(text), batch_size)\n",
    "    ]\n",
    "\n",
    "    for batch in tqdm(batches):\n",
    "        batch = [normalizer.normalize(t) for t in batch]\n",
    "\n",
    "        inputs = mul_en_tokenizer(\n",
    "            batch, return_tensors=\"pt\",\n",
    "            padding=True, truncation=True,\n",
    "            max_length=128).to(device)\n",
    "        tokens = mul_en_model.generate(**inputs)\n",
    "        result = [mul_en_tokenizer.decode(\n",
    "            t.squeeze(), skip_special_tokens=True)\n",
    "                  for t in tokens]\n",
    "        translations.extend(result)\n",
    "    return translations\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "\n",
    "for code in codes:\n",
    "    translations = batch_translate(text[code])\n",
    "    source.extend([f'>>{code}<< {t}' for t in translations])\n",
    "    target.extend(text[code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69507d3d-58a7-4991-a26d-7aab16f578c1",
   "metadata": {},
   "source": [
    "If for any examples the source is supiciously similar to the target, then it may actually be English rather than a local language. Filter these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a52bb-a46c-4cd7-af09-69e96ef20e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_format(input, first_word_title_case = True): \n",
    "    '''Ensure capital letter at the start and full stop at the end.'''\n",
    "    input = input[0].capitalize() + input[1:]\n",
    "    if input[-1] not in ['.', '!', '?']:\n",
    "        input = input + '.'\n",
    "    return input\n",
    "\n",
    "filtered_source = []\n",
    "filtered_target = []\n",
    "\n",
    "for s, t in zip(source, target):\n",
    "    d = levenshtein_distance(s, t)\n",
    "    might_be_english = (len(t) > 30) and ((d / len(t)) < 0.4)  \n",
    "    if not might_be_english:\n",
    "        filtered_source.append(s)\n",
    "        filtered_target.append(sentence_format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7701d7-abcf-4118-bbb1-6fae21a9de98",
   "metadata": {},
   "source": [
    "Create the back-translation training data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034a13b-b200-4cfd-8034-ab6257120b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"v7-dataset/v7.0/supervised/en-mul/back_translated.src\", \"w\") as f:\n",
    "    f.writelines('\\n'.join(filtered_source))\n",
    "with open(\"v7-dataset/v7.0/supervised/en-mul/back_translated.tgt\", \"w\") as f:\n",
    "    f.writelines('\\n'.join(filtered_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965ba61-6b49-46a7-891d-2addd8370d9b",
   "metadata": {},
   "source": [
    "## Translate English text for training mul-en model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b761080-dd04-42e3-9861-e5d81aab585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_text = file_to_list('back_translation/eng/daily-monitor.txt')\n",
    "eng_text = list(set(eng_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d9781-7e2c-490e-8a81-8d1b276c93bb",
   "metadata": {},
   "source": [
    "For each English sentence, choose one of the five other languages randomly to translate to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139c5bb-e642-4eb5-9b4f-1fc59c1b1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = []\n",
    "target = []\n",
    "\n",
    "# Split the text up into batches that will fit on the GPU\n",
    "batch_size = 20\n",
    "batches = [\n",
    "    eng_text[i:i + batch_size]\n",
    "    for i in range(0, len(eng_text), batch_size)\n",
    "]\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    batch = [sentence_format(normalizer.normalize(t))\n",
    "             for t in batch]\n",
    "\n",
    "    # Randomly select language codes\n",
    "    target_codes = np.random.choice(\n",
    "        language_codes, len(batch), replace=True)\n",
    "    source_text = [f'>>{code}<< {t}'\n",
    "                   for t, code in zip(batch, target_codes)]\n",
    "\n",
    "    inputs = en_mul_tokenizer(\n",
    "        source_text, return_tensors=\"pt\",\n",
    "        padding=True, truncation=True,\n",
    "        max_length=128).to(device)\n",
    "    tokens = en_mul_model.generate(**inputs)\n",
    "    translations = [en_mul_tokenizer.decode(\n",
    "        t.squeeze(), skip_special_tokens=True)\n",
    "              for t in tokens]\n",
    "\n",
    "    source.extend(translations)\n",
    "    target.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79641521-6a88-4d5e-90a3-47614668ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"v7-dataset/v7.0/supervised/mul-en/back_translated.src\", \"w\") as f:\n",
    "    f.writelines('\\n'.join(source))\n",
    "with open(\"v7-dataset/v7.0/supervised/mul-en/back_translated.tgt\", \"w\") as f:\n",
    "    f.writelines('\\n'.join(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4075a-18e4-471d-acfc-61da368e8b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
