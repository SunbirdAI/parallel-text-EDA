{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use the google API to forward and backtranslate data leading to an indirect distillation/piggybacking of the trained google models.\n",
    "\n",
    "Backtranslation is translation of monolingual text from the target sentences to monolingual text in the source sentences, usually using a pretrained translation model. This data is then fed into the model's training data and used to finetune the model. Forward translation utilizes mono-lingual data in the source language, which is usually less effective, since the same model is used to translate the data and retrain on it.\n",
    "\n",
    "In this case we use google's translation API, therefore both directions are valid. Since we are training on the translation results of a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import translate_v2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the necessary ggl language codes here https://cloud.google.com/translate/docs/languages\n",
    "config = {\n",
    "    \"source_language_ggl_token\": \"en\",\n",
    "    \"source_language_iso_token\": \"eng\",\n",
    "    \"target_language_ggl_token\": \"lg\",\n",
    "    \"target_language_iso_token\": \"lug\",\n",
    "    \"monolingual_data_dir\": \"back_translation/data\",\n",
    "    \"output_data_dir\": \"back_translation/google_bt\",\n",
    "    #\"temp_data_dir\": \"/temp/temp_bt_files\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'automlzero' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ali/.pyenv/versions/automlzero/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "## Todo: Add config dict\n",
    "sentences = []\n",
    "files_to_code = os.listdir(config[\"monolingual_data_dir\"])\n",
    "for file_to_read in files_to_code:\n",
    "    if file_to_read.startswith(\".\"):\n",
    "        continue\n",
    "    with open(os.path.join(config[\"monolingual_data_dir\"],file_to_read)) as lfd: \n",
    "        print(file_to_read)\n",
    "        lines = lfd.readlines()\n",
    "    sentences.extend(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated cost per run (7/3/2023 pricing)\n",
    "\n",
    "First 500k characters are at a standard rate of 10$\n",
    "500k-1bn characters are at 20$/10^6 characters using the Basic Translation API and no src language detection. \n",
    "\n",
    "This is the pricing we will use to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'automlzero' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ali/.pyenv/versions/automlzero/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "total_count = 0\n",
    "for sentence in tqdm(sentences):\n",
    "    total_count += len(sentence)\n",
    "\n",
    "total_price = (total_count/1000000)*20\n",
    "print(f\"Estimated cost of this run is ${total_price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'automlzero' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ali/.pyenv/versions/automlzero/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "path_to_google_srv_account_json = \"/enter/your/own/path/here\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_google_srv_account_json\n",
    "\n",
    "# or comment the previous lines and use the environment variable directly from bash, docker, etc.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create temp versions of the data to avoid corrupting the monolingual dataset in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'automlzero' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ali/.pyenv/versions/automlzero/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "translate_client = translate_v2.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is wise to start with a smaller subset to ensure everything works, before running the whole batch and finding out there is an error after credits have been spent\n",
    "\n",
    "starting_idx = 0\n",
    "end_index = 50 #len(sentences)\n",
    "step_size = 10 #100\n",
    "\n",
    "combined_file = os.path.join(config[\"output_data_dir\"], f\"combined-{config['source_language_iso_token']}-{config['target_language_iso_token']}-data.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "translated_scentences = []\n",
    "\n",
    "\n",
    "def _get_string(line_dict):\n",
    "    return \"\".join([line_dict[\"translatedText\"], \"__SEP__\", line_dict[\"input\"]])\n",
    "\n",
    "for current_idx in tqdm(range(starting_idx, end_index,step_size )):\n",
    "    prev_length = len(translated_scentences)\n",
    "    print(f\"Current IDX: {current_idx} END_IDX: {end_index} STEPSIZE: {step_size}\")\n",
    "    if current_idx+step_size < end_index:\n",
    "        segment_to_translate = sentences[current_idx:current_idx+step_size]\n",
    "    else: \n",
    "        segment_to_translate = sentences[current_idx:end_index]\n",
    "\n",
    "    try:\n",
    "        fresh_off_the_translator = translate_client.translate(\n",
    "            segment_to_translate,\n",
    "            source_language=config[\"source_language_ggl_token\"], \n",
    "            target_language=config[\"target_language_ggl_token\"]\n",
    "            )\n",
    "        sleep(5)\n",
    "        translated_scentences.extend(fresh_off_the_translator)\n",
    "        if type(fresh_off_the_translator) == list:\n",
    "            for line_dict in fresh_off_the_translator: \n",
    "                str_to_write = _get_string(line_dict)\n",
    "                with open(combined_file, \"a\") as tfd:\n",
    "                    tfd.write(str_to_write + \"\\n\")\n",
    "        elif type(fresh_off_the_translator) == dict:\n",
    "            str_to_write = _get_string(fresh_off_the_translator)\n",
    "            with open(combined_file, \"a\") as tfd:\n",
    "                tfd.write(str_to_write + \"\\n\")\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected Value\")\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"stopped at: \" + str(current_idx))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'automlzero' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ali/.pyenv/versions/automlzero/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "words_df = pd.read_csv(combined_file, delimiter=\"__SEP__\", names=[config[\"source_language_iso_token\"], config[\"target_language_iso_token\"]])\n",
    "output_file_name = f'backtranslated-from-{config[\"source_language_iso_token\"]}-to-{config[\"target_language_iso_token\"]}.jsonl'\n",
    "path_to_output = os.path.join(config[\"output_data_dir\"], output_file_name)\n",
    "\n",
    "for sentence_idx in range(len(words_df)):\n",
    "    src_sentence = words_df.iloc[sentence_idx][config[\"source_language_iso_token\"]]\n",
    "    tgt_sentence = words_df.iloc[sentence_idx][config[\"target_language_iso_token\"]]\n",
    "    dict_to_dump = {\n",
    "        \"text\": {\n",
    "            config[\"source_language_iso_token\"]: src_sentence,\n",
    "            config[\"target_language_iso_token\"]: tgt_sentence\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(path_to_output, \"a\") as fd:\n",
    "        #with open(\"test.txt\", \"a\") as fd:\n",
    "        fd.write(json.dumps(dict_to_dump)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automlzero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e56a3f7d6087dc0e8010c68576613beaec95fa9bfb8de85e967e8c762a16959e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
