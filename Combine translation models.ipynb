{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c744627-5999-41de-a6c0-b080e8767388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sacremoses\n",
    "import transformers\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86423a70-cbb1-4fa9-be42-4e2194ee5753",
   "metadata": {},
   "source": [
    "## Create a combined `en-mul` and `mul-en` model\n",
    "\n",
    "We create here a single model which can do translation in both directions. This can be useful for endpoint hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9c277e-5d80-495b-ac2e-81cd9b3f3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths accordingly\n",
    "mul_en_checkpoint_path = \"savedmodels/mul-en\"\n",
    "mul_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    mul_en_checkpoint_path)\n",
    "mul_en_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    mul_en_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da546a0-a64c-464b-a7c9-751fc4c139d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_mul_checkpoint_path = \"savedmodels/en-mul\"\n",
    "en_mul_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    en_mul_checkpoint_path)\n",
    "en_mul_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    en_mul_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab916e0-3af8-48df-83ac-a81dba24bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedTranslationModel(torch.nn.Module):\n",
    "    def __init__(self, en_mul_model, mul_en_model):\n",
    "        super(CombinedTranslationModel, self).__init__()\n",
    "        self.en_mul_model = en_mul_model\n",
    "        self.mul_en_model = mul_en_model  \n",
    "        \n",
    "    def generate(self, target_language, **inputs):\n",
    "        if target_language == 'en':\n",
    "            x = self.mul_en_model.generate(**inputs)\n",
    "        else:\n",
    "            x = self.en_mul_model.generate(**inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ca9915d-71a3-4d8b-89bc-daea2afc2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = CombinedTranslationModel(en_mul_model, mul_en_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac9d81-695e-4153-aa80-774de0117cae",
   "metadata": {},
   "source": [
    "## Example of using the combined model for translation\n",
    "\n",
    "This is the same as usual, but notice the extra parameter `target_language` passed to `model.generate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdec9e7-4586-4c01-8fc1-f5de5d8a3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(source_text, model, tokenizer, target_language):\n",
    "    device = torch.device('cpu')\n",
    "    model = model.eval()\n",
    "    model = model.to(device) \n",
    "    inputs = tokenizer(source_text, return_tensors=\"pt\").to(device)\n",
    "    tokens = model.generate(target_language, **inputs)\n",
    "    result = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b0456-3375-40d1-ba09-2e4e2a22e538",
   "metadata": {},
   "source": [
    "Watch out that the right tokenizer is used (`en-mul` or `mul-en`), otherwise the output will be unintelligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0db6936-ee10-4b9c-a4ba-05859cdd3018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have four legs.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Nina amagulu ana', combined_model,\n",
    "          mul_en_tokenizer, target_language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9350a058-4535-4dde-9ce9-6f2ee68d393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Erinnya lyange Bainomugisha.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('>>lug<< My name is Bainomugisha', combined_model,\n",
    "          en_mul_tokenizer, target_language='mul')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e026251-9929-4613-a57a-c3d96bd0ddb8",
   "metadata": {},
   "source": [
    "## Test loading and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdd74eb6-cfbd-4bea-90d3-27aaa7bb154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(combined_model, 'savedmodels/combined.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef686ccb-bc98-491c-968b-3b8240e73961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedTranslationModel(torch.nn.Module):\n",
    "    def __init__(self, en_mul_model, mul_en_model):\n",
    "        super(CombinedTranslationModel, self).__init__()\n",
    "        self.en_mul_model = en_mul_model\n",
    "        self.mul_en_model = mul_en_model  \n",
    "        \n",
    "    def generate(self, target_language, **inputs):\n",
    "        if target_language == 'en':\n",
    "            x = self.mul_en_model.generate(**inputs)\n",
    "        else:\n",
    "            x = self.en_mul_model.generate(**inputs)\n",
    "        return x\n",
    "    \n",
    "loaded_model = torch.load('savedmodels/combined.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987fe99e-b3b1-4f23-b576-d4e345aef705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are you doing?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Okola ki?', loaded_model,\n",
    "          mul_en_tokenizer, target_language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6d9fde7-eba8-456a-b706-21eb5f0d845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nze kompyuta.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('>>lug<< I am a computer', loaded_model,\n",
    "          en_mul_tokenizer, target_language='mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c4d6d-8c2c-4b41-8a35-16db7d9700fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
