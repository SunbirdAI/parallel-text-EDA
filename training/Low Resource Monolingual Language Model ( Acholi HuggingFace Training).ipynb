{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b06e57"
      },
      "source": [
        "## Imports and setup"
      ],
      "id": "13b06e57"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ce02158"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "!pip install evaluate\n",
        "!pip install nltk\n",
        "!pip install transformers\n",
        "!pip install sacrebleu\n",
        "!pip install sacremoses\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install sentencepiece\n",
        "display.clear_output()"
      ],
      "id": "9ce02158"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "Pzds2nSQ0crE"
      },
      "id": "Pzds2nSQ0crE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "36461e69"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import evaluate\n",
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import sentencepiece\n",
        "import sacrebleu\n",
        "import sacremoses\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "import transformers\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "from transformers import TrainingArguments, Trainer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "from transformers import AutoConfig\n",
        "\n"
      ],
      "id": "36461e69"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c875def4-aa4a-46b1-ac1b-71e8702dcdba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9613de88-1924-4a55-d40c-40d859dff30c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ],
      "id": "c875def4-aa4a-46b1-ac1b-71e8702dcdba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ea76c66"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Pretraining on the GPT2 Swahili model 'flax-community/gpt2-swahili'\n",
        "\n"
      ],
      "id": "3ea76c66"
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "64b27659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cfd9c5-c64c-46ab-88e3-dfbff48e23c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating every 1000 training steps.\n"
          ]
        }
      ],
      "source": [
        "# Parameters for mul-en models\n",
        "config = {\n",
        "    'metric_for_best_model': 'eval_loss',\n",
        "    'metric_for_best_model_dir': 'min',\n",
        "    'train_batch_size': 1,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'max_input_length': 32,\n",
        "    'max_target_length': 32,\n",
        "    'eval_batch_size': 1,\n",
        "    'eval_pretrained_model': True,\n",
        "    'learning_rate': 1e-4,\n",
        "    'num_train_epochs': 3,\n",
        "    'label_smoothing_factor': 0.1,\n",
        "    'use_cache': False\n",
        "}\n",
        "\n",
        "config['wandb_project'] = f'salt-monolingual'\n",
        "config['wandb_entity'] = f'sunbird'\n",
        "config['model_checkpoint'] = f'flax-community/gpt2-swahili'\n",
        "\n",
        "# What training data to use\n",
        "\n",
        "# Evaluate roughly every 10 minutes\n",
        "eval_steps_interval = 1000\n",
        "\n",
        "\n",
        "print(f'Evaluating every {eval_steps_interval} training steps.')\n",
        "\n"
      ],
      "id": "64b27659"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    weight_decay = 0.01,\n",
        "    output_dir=\"./gpt2-luo\", #The output directory\n",
        "    save_total_limit = 3,\n",
        "    fp16 = torch.cuda.is_available(),\n",
        "    load_best_model_at_end=True,\n",
        "    run_name = f'monolingual-acholi',\n",
        "    eval_steps = eval_steps_interval,\n",
        "    save_steps = eval_steps_interval,\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=config['num_train_epochs'], # number of training epochs\n",
        "    per_device_train_batch_size=config[\"train_batch_size\"], # batch size for training\n",
        "    per_device_eval_batch_size=config[\"eval_batch_size\"],  # batch size for evaluation\n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    metric_for_best_model = config['metric_for_best_model'],\n",
        "    report_to = 'none',\n",
        "    logging_dir = f'monolingual-acholi',\n",
        "    label_smoothing_factor = config['label_smoothing_factor'],\n",
        "    #predict_with_generate = True,\n",
        "    evaluation_strategy = 'steps',\n",
        "    gradient_accumulation_steps = config['gradient_accumulation_steps'],\n",
        "    learning_rate = config['learning_rate'],\n",
        "\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "rPxQ3r93KzDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5ba82e-beee-42c3-9884-b3985bb107ac"
      },
      "id": "rPxQ3r93KzDU",
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config['training_dir'] = '/content/monolingual_acholi'\n",
        "config['training_subset_ids'] = [\n",
        "        'acholi-online.txt', \n",
        "        'misc.txt',\n",
        "        'train_flores_luo.src', \n",
        "        #'train_mt560_luo.src', \n",
        "    ]\n",
        "#'val_ach.src', 'test_ach.src' are not included in training to avoid leakage\n",
        "\n",
        "\n",
        "config['valid_subset_ids'] = [\n",
        "        'val_ach.src'\n",
        "            ]\n",
        "\n",
        "config['test_subset_ids'] = [\n",
        "        'test_ach.src'\n",
        "    ]"
      ],
      "metadata": {
        "id": "gwCnloIBT_AN"
      },
      "id": "gwCnloIBT_AN",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dade6a8-9f93-4d64-8fec-e4462bf425e9"
      },
      "source": [
        "MT560 is much bigger than the other training sets, so oversample the rest (by 5x) to balance it out."
      ],
      "id": "0dade6a8-9f93-4d64-8fec-e4462bf425e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f607807-40be-4cda-8fa7-67abb72f0234"
      },
      "source": [
        "# Set up datasets\n",
        "\n",
        "Download the raw text data."
      ],
      "id": "9f607807-40be-4cda-8fa7-67abb72f0234"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "29dcda22-59ab-49b3-b2fd-5a8b200dead2"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('v7-dataset'):\n",
        "    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/v7-dataset.zip\n",
        "    !unzip v7-dataset.zip\n",
        "    display.clear_output()"
      ],
      "id": "29dcda22-59ab-49b3-b2fd-5a8b200dead2"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://mekaneeky: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@github.com/SunbirdAI/parallel-text-EDA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-t8iiiVDBVn",
        "outputId": "a71222eb-4d4c-4aa8-d770-ecede3487998"
      },
      "id": "C-t8iiiVDBVn",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'parallel-text-EDA'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 207 (delta 6), reused 11 (delta 3), pack-reused 193\u001b[K\n",
            "Receiving objects: 100% (207/207), 4.86 MiB | 8.15 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir monolingual_acholi\n",
        "!cp /content/parallel-text-EDA/back_translation/data/ach/* /content/monolingual_acholi/\n",
        "!cp /content/v7-dataset/v7.0/supervised/mul-en/train_flores_luo.src /content/monolingual_acholi/\n",
        "#!cp /content/v7-dataset/v7.0/supervised/mul-en/train_mt560_luo.src /content/monolingual_acholi/\n",
        "!cp /content/v7-dataset/v7.0/supervised/mul-en/val_ach.src /content/monolingual_acholi/\n",
        "!cp /content/v7-dataset/v7.0/supervised/mul-en/test_ach.src /content/monolingual_acholi/\n"
      ],
      "metadata": {
        "id": "0J7PGRZfT1SE"
      },
      "id": "0J7PGRZfT1SE",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "dda8c8a2"
      },
      "outputs": [],
      "source": [
        "def sentence_format(input):\n",
        "    '''Ensure capital letter at the start and full stop at the end.'''\n",
        "    input = input[0].capitalize() + input[1:]\n",
        "    if input[-1] not in ['.', '!', '?']:\n",
        "        input = input + '.'\n",
        "    return input\n",
        "\n",
        "def preprocess(examples):\n",
        "\n",
        "    normalizer = sacremoses.MosesPunctNormalizer()\n",
        "\n",
        "    inputs_ids= [sentence_format(normalizer.normalize(text))\n",
        "              for text in examples[\"input_ids\"]]\n",
        "    \n",
        "    examples = tokenizer(\n",
        "        inputs_ids,padding=\"max_length\", \n",
        "        max_length=config[\"max_input_length\"], \n",
        "        truncation=True, \n",
        "        return_overflowing_tokens=True, \n",
        "        return_length=True,\n",
        "        return_tensors=\"pt\"\n",
        "        )\n",
        "    \n",
        "    input_batch = []\n",
        "    for length, input_ids in zip(examples[\"length\"], examples[\"input_ids\"]):\n",
        "        if length == config[\"max_input_length\"]:\n",
        "            input_batch.append(input_ids)\n",
        "\n",
        "    return {\"input_ids\": input_batch}\n",
        "    \n",
        "    #examples[\"labels\"] = examples[\"input_ids\"].detach().clone()\n",
        "\n",
        "    return examples\n",
        "\n",
        "def postprocess(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n"
      ],
      "id": "dda8c8a2"
    },
    {
      "cell_type": "code",
      "source": [
        "sum([sum(1 for line in open('/content/monolingual_acholi/acholi-online.txt')),\n",
        "     sum(1 for line in open('/content/monolingual_acholi/misc.txt')),\n",
        "     sum(1 for line in open('/content/monolingual_acholi/rupiny.txt')),\n",
        "     sum(1 for line in open('/content/v7-dataset/v7.0/supervised/mul-en/train_flores_luo.src')),\n",
        "     #sum(1 for line in open('/content/v7-dataset/v7.0/supervised/mul-en/train_mt560_luo.src'))\n",
        "     \n",
        "     ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-gXpb90OwE8",
        "outputId": "8234e213-cbe5-4ee9-aa0a-bf0fbd19f212"
      },
      "id": "F-gXpb90OwE8",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10642"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "def _files_to_list(path):\n",
        "    lines_file = []\n",
        "    with open(path) as file:\n",
        "        lines_file = file.readlines()\n",
        "        lines_file = [line.rstrip() for line in lines_file]\n",
        "    \n",
        "    return lines_file\n",
        "    \n",
        "def dataset_from_src_tgt_files(data_dir = config[\"training_dir\"], validation_cutoff = 8500, test_cutoff = 9000):\n",
        "    \"\"\"\n",
        "        validation_cutoff: use first n lines as validation\n",
        "    \"\"\"\n",
        "\n",
        "    train_text= []\n",
        "    valid_text = []\n",
        "    test_text = []\n",
        "    for file_name in config[\"training_subset_ids\"]:\n",
        "        path = os.path.join(data_dir, file_name)\n",
        "        file_text  = _files_to_list(path )\n",
        "        random.shuffle(file_text)\n",
        "        train_text.extend( file_text[:validation_cutoff])\n",
        "        valid_text.extend( file_text[validation_cutoff:test_cutoff])\n",
        "        test_text.extend( file_text[test_cutoff:])\n",
        "\n",
        "    for file_name in config[\"valid_subset_ids\"]:\n",
        "        path = os.path.join(data_dir, file_name)\n",
        "        file_text  = _files_to_list(path )\n",
        "        valid_text.extend( file_text )\n",
        "\n",
        "\n",
        "    for file_name in config[\"test_subset_ids\"]:\n",
        "        path = os.path.join(data_dir, file_name)\n",
        "        file_text  = _files_to_list(path )\n",
        "        test_text.extend( file_text )\n",
        "\n",
        "\n",
        "    return datasets.Dataset.from_dict({'input_ids': train_text}), \\\n",
        "           datasets.Dataset.from_dict({'input_ids': valid_text}), \\\n",
        "           datasets.Dataset.from_dict({'input_ids': test_text}), "
      ],
      "metadata": {
        "id": "PttVruj_KSrr"
      },
      "id": "PttVruj_KSrr",
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9331d9b"
      },
      "source": [
        "Pre-process the raw text datasets."
      ],
      "id": "e9331d9b"
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_raw, valid_data_raw, test_data_raw =   dataset_from_src_tgt_files()"
      ],
      "metadata": {
        "id": "VKdTP3DLhILf"
      },
      "id": "VKdTP3DLhILf",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_config.use_cache = False"
      ],
      "metadata": {
        "id": "cdk2CMB0I-hX"
      },
      "id": "cdk2CMB0I-hX",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "59977cde"
      },
      "outputs": [],
      "source": [
        "\n",
        "pretrained_config = AutoConfig.from_pretrained(\"flax-community/gpt2-swahili\")\n",
        "pretrained_config.task_specific_params[\"text-generation\"][\"max_length\"] = config[\"max_input_length\"]\n",
        "pretrained_config.use_cache = config[\"use_cache\"]\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"flax-community/gpt2-swahili\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelWithLMHead.from_pretrained(\"flax-community/gpt2-swahili\", config=pretrained_config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False)\n",
        "training_args.vocab_size = tokenizer.vocab_size\n",
        "#data_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model = model) \n",
        "#metric = datasets.load_metric('sacrebleu')\n",
        "display.clear_output()"
      ],
      "id": "59977cde"
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "ffd05d31-b8e2-4049-bbb4-8abbeafacbf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9588f817055d40d79936dd7c6b3b13d8",
            "1d16cc4ebcb340fc9619e68474c251c3",
            "7980709188a346738820121498fc2628",
            "5edca9ea0b1b4a4d894659d2af109f85",
            "fefeef2dce1249d6af03b10bd25e85b7",
            "8034d66664b448fc80a43d0f4e9a498e",
            "e1ecce17d24842f4acfe3604884e45de",
            "0aabdd0487d8429e91d1ab079ae02551",
            "f04ff0e1a8844043b339441c787eef78",
            "f9e626f5531343e88b384ff81c8697c1",
            "0a02cb117a344fdc831a67ab62fbc48a",
            "6adcb6f196fa485e9849e4ba1d446032",
            "09abfd3f34a8495382595a328c70730f",
            "4e2e050b992747079f854d5fe4856782",
            "2eace212dcb8436faee7b37035608b68",
            "d11757a4cf444860af2ea9daacf208a3",
            "dc5aa269808d407ea4b87bb9759f1f2b",
            "8aa609f1190444b29b98ccbe926d796d",
            "e48c7ea7153647868ccf9a7ba67509eb",
            "3247ad8d13fc495c9c8cdd2f5110377c",
            "a195cf9042ca4555b488cd9e15ba2811",
            "a30f212c81c249f292be38bd88a9bea9",
            "40a2be2d2b134cf5a06efd4cb649bb82",
            "5977645006224e5ba35f1936146b7a87",
            "d9f4d83e7cce4947a1e27e98f5fbff0f",
            "87d0d41c410248148c2f46201f2267c0",
            "718311e6c6b145f39215c62bf3d6d3bf",
            "73d37703e8bd400dbc58963509c91809",
            "311ea9463938447da7e1d5b82950e053",
            "27bea33b3219468ab73b07e5acf1f254",
            "2ec2360a35a44d56b0938483fde3b2ff",
            "0b9a56796ff443bf86be582cbc6b9d77",
            "c608995de99047b5a473aa90371a0719"
          ]
        },
        "outputId": "f5457c98-83d1-4ff3-dee4-45cf4ebb187c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9588f817055d40d79936dd7c6b3b13d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6adcb6f196fa485e9849e4ba1d446032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40a2be2d2b134cf5a06efd4cb649bb82"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data  = train_data_raw.map(\n",
        "    preprocess, batched=True)\n",
        "\n",
        "validation_data  = valid_data_raw.map(\n",
        "    preprocess, batched=True)\n",
        "\n",
        "subset_validation_data = Subset(validation_data, [i for i in range(500)])\n",
        "\n",
        "test_data = test_data_raw.map(\n",
        "    preprocess, batched=True)\n"
      ],
      "id": "ffd05d31-b8e2-4049-bbb4-8abbeafacbf8"
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Eknan48EpH",
        "outputId": "ef3dba69-8473-46f5-f73b-e54bd82ccdf5"
      },
      "id": "G-Eknan48EpH",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids'],\n",
              "    num_rows: 4356\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0].keys()"
      ],
      "metadata": {
        "id": "8gP3gbKP3FCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e58d92-890e-434b-9f30-556b18618ead"
      },
      "id": "8gP3gbKP3FCi",
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a0ec59a"
      },
      "source": [
        "Launch the training."
      ],
      "id": "7a0ec59a"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    text = output\n",
        "except:\n",
        "    text = \"Sina pesa \"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "tokens= model.generate(encoded_input[\"input_ids\"])\n",
        "output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HIItiSVtQDD",
        "outputId": "a7983045-ec9a-4fd0-c855-0ec7b48e5de1"
      },
      "id": "3HIItiSVtQDD",
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 29, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sina pesa!\"\"Unanidai nini?\"\"Unanidai pesa nyingi sana, na mimi nina pesa nyingi sana, na nina pesa nyingi sana,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outp = model(encoded_input[\"input_ids\"].cuda())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "VWb2TzRuGL4C",
        "outputId": "c6974051-87f2-40e1-e65d-323cd5b959cc"
      },
      "id": "VWb2TzRuGL4C",
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-32b762580e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "metadata": {
        "id": "h81h4RtYMzS1"
      },
      "id": "h81h4RtYMzS1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=subset_validation_data,\n",
        "    #compute_metrics= compute_metrics\n",
        "    )"
      ],
      "metadata": {
        "id": "yJql0DPnDnHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c45a35-983d-41dc-ace7-dfb79ee6ae7a"
      },
      "id": "yJql0DPnDnHd",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "vFnXC6m2mhIQ",
        "outputId": "fbf700e3-0959-4938-af8e-e725ee13da52"
      },
      "id": "vFnXC6m2mhIQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12951\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 38853\n",
            "  Number of trainable parameters = 124446720\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2281' max='38853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2281/38853 04:12 < 1:07:37, 9.01 it/s, Epoch 0.18/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.274200</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.756700</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./gpt2-luo/checkpoint-1000\n",
            "Configuration saved in ./gpt2-luo/checkpoint-1000/config.json\n",
            "Configuration saved in ./gpt2-luo/checkpoint-1000/generation_config.json\n",
            "Model weights saved in ./gpt2-luo/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./gpt2-luo/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./gpt2-luo/checkpoint-1000/special_tokens_map.json\n",
            "Deleting older checkpoint [gpt2-luo/checkpoint-100] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./gpt2-luo/checkpoint-2000\n",
            "Configuration saved in ./gpt2-luo/checkpoint-2000/config.json\n",
            "Configuration saved in ./gpt2-luo/checkpoint-2000/generation_config.json\n",
            "Model weights saved in ./gpt2-luo/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./gpt2-luo/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./gpt2-luo/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [gpt2-luo/checkpoint-600] due to args.save_total_limit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Garbage collection cell to free up VRAM, run only if you want to delete the model data from memory and start again"
      ],
      "metadata": {
        "id": "zuU_jMr_noy0"
      },
      "id": "zuU_jMr_noy0"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "model.cpu()\n",
        "del model\n"
      ],
      "metadata": {
        "id": "cRcmz6dzOjxE"
      },
      "id": "cRcmz6dzOjxE",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1/0\n"
      ],
      "metadata": {
        "id": "xaBGa5cA_ilE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "e812d166-2623-4378-95f7-c63698b8b402"
      },
      "id": "xaBGa5cA_ilE",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFeCdoIU6IOQ"
      },
      "id": "iFeCdoIU6IOQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9588f817055d40d79936dd7c6b3b13d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d16cc4ebcb340fc9619e68474c251c3",
              "IPY_MODEL_7980709188a346738820121498fc2628",
              "IPY_MODEL_5edca9ea0b1b4a4d894659d2af109f85"
            ],
            "layout": "IPY_MODEL_fefeef2dce1249d6af03b10bd25e85b7"
          }
        },
        "1d16cc4ebcb340fc9619e68474c251c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8034d66664b448fc80a43d0f4e9a498e",
            "placeholder": "​",
            "style": "IPY_MODEL_e1ecce17d24842f4acfe3604884e45de",
            "value": "100%"
          }
        },
        "7980709188a346738820121498fc2628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aabdd0487d8429e91d1ab079ae02551",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f04ff0e1a8844043b339441c787eef78",
            "value": 9
          }
        },
        "5edca9ea0b1b4a4d894659d2af109f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e626f5531343e88b384ff81c8697c1",
            "placeholder": "​",
            "style": "IPY_MODEL_0a02cb117a344fdc831a67ab62fbc48a",
            "value": " 9/9 [00:01&lt;00:00,  5.09ba/s]"
          }
        },
        "fefeef2dce1249d6af03b10bd25e85b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8034d66664b448fc80a43d0f4e9a498e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ecce17d24842f4acfe3604884e45de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aabdd0487d8429e91d1ab079ae02551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04ff0e1a8844043b339441c787eef78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9e626f5531343e88b384ff81c8697c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a02cb117a344fdc831a67ab62fbc48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6adcb6f196fa485e9849e4ba1d446032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09abfd3f34a8495382595a328c70730f",
              "IPY_MODEL_4e2e050b992747079f854d5fe4856782",
              "IPY_MODEL_2eace212dcb8436faee7b37035608b68"
            ],
            "layout": "IPY_MODEL_d11757a4cf444860af2ea9daacf208a3"
          }
        },
        "09abfd3f34a8495382595a328c70730f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5aa269808d407ea4b87bb9759f1f2b",
            "placeholder": "​",
            "style": "IPY_MODEL_8aa609f1190444b29b98ccbe926d796d",
            "value": "100%"
          }
        },
        "4e2e050b992747079f854d5fe4856782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48c7ea7153647868ccf9a7ba67509eb",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3247ad8d13fc495c9c8cdd2f5110377c",
            "value": 5
          }
        },
        "2eace212dcb8436faee7b37035608b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a195cf9042ca4555b488cd9e15ba2811",
            "placeholder": "​",
            "style": "IPY_MODEL_a30f212c81c249f292be38bd88a9bea9",
            "value": " 5/5 [00:00&lt;00:00,  5.51ba/s]"
          }
        },
        "d11757a4cf444860af2ea9daacf208a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5aa269808d407ea4b87bb9759f1f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa609f1190444b29b98ccbe926d796d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48c7ea7153647868ccf9a7ba67509eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3247ad8d13fc495c9c8cdd2f5110377c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a195cf9042ca4555b488cd9e15ba2811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30f212c81c249f292be38bd88a9bea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40a2be2d2b134cf5a06efd4cb649bb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5977645006224e5ba35f1936146b7a87",
              "IPY_MODEL_d9f4d83e7cce4947a1e27e98f5fbff0f",
              "IPY_MODEL_87d0d41c410248148c2f46201f2267c0"
            ],
            "layout": "IPY_MODEL_718311e6c6b145f39215c62bf3d6d3bf"
          }
        },
        "5977645006224e5ba35f1936146b7a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d37703e8bd400dbc58963509c91809",
            "placeholder": "​",
            "style": "IPY_MODEL_311ea9463938447da7e1d5b82950e053",
            "value": "100%"
          }
        },
        "d9f4d83e7cce4947a1e27e98f5fbff0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27bea33b3219468ab73b07e5acf1f254",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ec2360a35a44d56b0938483fde3b2ff",
            "value": 5
          }
        },
        "87d0d41c410248148c2f46201f2267c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9a56796ff443bf86be582cbc6b9d77",
            "placeholder": "​",
            "style": "IPY_MODEL_c608995de99047b5a473aa90371a0719",
            "value": " 5/5 [00:00&lt;00:00,  8.39ba/s]"
          }
        },
        "718311e6c6b145f39215c62bf3d6d3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d37703e8bd400dbc58963509c91809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311ea9463938447da7e1d5b82950e053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27bea33b3219468ab73b07e5acf1f254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec2360a35a44d56b0938483fde3b2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b9a56796ff443bf86be582cbc6b9d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c608995de99047b5a473aa90371a0719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}